{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# for developers\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on diffractem: v0.3.4-39-ga7d9500\n",
      "Running on CrystFEL: 0.9.1+f937b91c\n",
      "Current path is: /nas/localdata/30388/serialed/serialed-examples\n"
     ]
    }
   ],
   "source": [
    "# import hdf5plugin # required to access LZ4-encoded HDF5 data sets, if not on your global path\n",
    "import matplotlib.pyplot as plt\n",
    "from diffractem import version, proc2d, pre_proc_opts, io, tools\n",
    "from diffractem.dataset import Dataset\n",
    "from tifffile import imread\n",
    "import numpy as np\n",
    "from dask.distributed import Client, LocalCluster, TimeoutError\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "opts = pre_proc_opts.PreProcOpts('preproc.yaml')\n",
    "# opts.im_exc = 'indexamajig'\n",
    "cfver = !{opts.im_exc} -v\n",
    "print(f'Running on diffractem:', version())\n",
    "print(f'Running on', cfver[0])\n",
    "print(f'Current path is:', os.getcwd())\n",
    "\n",
    "pxmask=imread(opts.pxmask)\n",
    "reference=imread(opts.reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of dose-fractionated data sets\n",
    "...which is ideally done after once running the full workflow including indexing, or even merging.\n",
    "Essentially, it starts by creating processed data files, which works very simiarly to `preprocessing.ipynb`.\n",
    "In this script, we will prepare a dataset with aggregated frames 0+1+2, as well as files containing all frames separately, or a cumulative sum of them.\n",
    "\n",
    "Then, `.stream` files with integrated intensities are derived from the already knwon indexing solutions -- similarly to the re-integration as explained in `indexing.ipynb`.\n",
    "\n",
    "After running this notebook, you will have new stream files - one with a different aggregation, one with all single shots, and one with all different aggregations (cumulated single shots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cluster scheduler found and connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>20</li>\n",
       "  <li><b>Cores: </b>40</li>\n",
       "  <li><b>Memory: </b>540.64 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:8786' processes=20 threads=40, memory=540.64 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_port = 8786\n",
    "\n",
    "try:\n",
    "    client = Client(address=f'127.0.0.1:{cluster_port}', timeout='2s')\n",
    "    print('Running cluster scheduler found and connected.')\n",
    "    client.run(os.chdir, os.getcwd()); # change the cluster to the current directory\n",
    "except (OSError, TimeoutError):\n",
    "    print('Seems no cluster scheduler is running. Starting one.')\n",
    "    cluster = LocalCluster(host=f'127.0.0.1:{cluster_port}', n_workers=20, threads_per_worker=2, \n",
    "                       local_directory='/scratch/distributed')\n",
    "    client = Client(address=f'127.0.0.1:{cluster_port}')\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the raw data set\n",
    "We start, just as in `preprocessing.ipynb`, by loading the raw data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 raw files. Have fun pre-processing!\n",
      "Persisting stacks to memory: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diffractem Dataset object spanning 34 NeXus/HDF5 files\n",
       "-----\n",
       "55800 shots (55800 selected)\n",
       "2247 features\n",
       "1 data stacks: raw_counts\n",
       "Diffraction data stack: raw_counts\n",
       "Data files open: True\n",
       "Data files writable: False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.load() # re-load parameters from the .yaml file\n",
    "\n",
    "raw_files = io.expand_files('raw_data/*.nxs', validate=True)\n",
    "print(f'Found {len(raw_files)} raw files. Have fun pre-processing!')\n",
    "ds = Dataset.from_files(raw_files, chunking=50, )\n",
    "ds.merge_meta('/%/instrument/detector/collection/shutter_time')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting to another aggregation\n",
    "\n",
    "We now make an aggregation where we include the first frame (`frame==0`), which we omitted from the original aggregation we used for indexing etc., and only include the first three frames.\n",
    "\n",
    "### Preparing data files\n",
    "...works excatly as for the original aggregation, just that instead of `compute_pattern_info`, we use `merge_pattern_info`, in order to get the pattern information (peaks, center,...) from the `image_info.h5`.\n",
    "\n",
    "From there, it works exactly the same again: do your hit correction, compute the final image using `proc2d.correct_image`, check the outcome using `view`, and compute and save it.\n",
    "After indexing, you can use the newly made files for integration just as well (same as in `indexing.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monotonous aggregation: True \n",
      "File/subset remixing: False\n",
      "Frame aggregation: True\n",
      "Acq. run aggregation: False\n",
      "Discarding shot table columns: ['Event', 'frame', 'shot_in_subset']\n",
      "Persisting stacks to memory: \n",
      "Single-file dataset, disabling parallel I/O.\n",
      "No feature list in data set ('/%/map/features not found in image_info.h5.'). That's ok if it's a virtual or info file.\n",
      "Persisting stacks to memory: nPeaks, peakTotalIntensity, peakXPosRaw, peakYPosRaw\n",
      "Persisting stacks to memory: nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n",
      "1322 shots out of 2146 selected.\n",
      "Persisting stacks to memory: nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n"
     ]
    }
   ],
   "source": [
    "# now, e.g. make another aggregation...\n",
    "ds_0to2 = ds.aggregate(query='frame >= 0 and frame <= 2 and shutter_time == 2', \n",
    "                      by=['sample', 'region', 'run', 'crystal_id'], how='sum', \n",
    "                       new_folder='proc_data', file_suffix='_0to2.h5')\n",
    "ds_0to2.merge_pattern_info('image_info.h5')\n",
    "ds_0to2_hit = ds_0to2.get_selection(f'num_peaks > {opts.min_peaks}', file_suffix='_hit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2efba7052c41b4bad8797e1cc98468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Textarea(value='sample: Lyso190304\\nregion: 3\\nrun: 0\\ncrystal_id…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ...and correct the images\n",
    "opts.load()\n",
    "ds_compute = ds_0to2_hit\n",
    "img_final = proc2d.correct_image(ds_compute.raw_counts, opts,\n",
    "                                ds_compute.shots.lor_x.values,\n",
    "                                ds_compute.shots.lor_y.values,\n",
    "                                ds_compute.peak_data) # keep in mind, that this a lazy computation, so nothing is actually done yet\n",
    "\n",
    "ds_compute.add_stack('corrected', img_final, overwrite=True, set_diff_stack=True)\n",
    "ds_compute.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `ds_0to2_hit` has everything to be written to disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data files...\n",
      "Storing meta tables...\n",
      "Storing meta stacks nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n",
      "[########################################] | 100% Completed |  6.0s\n",
      "Storing diffraction data stack corrected... monitor progress at http://127.0.0.1:8787/status (or forward port if remote)\n",
      "Initializing data sets for diffraction stack corrected...\n",
      "Submitting tasks to dask.distributed scheduler...\n",
      "Starting computation...\n",
      "[########################################] | 100% Completed | 41.7s\r"
     ]
    }
   ],
   "source": [
    "ds_0to2_hit.compute_and_save(diff_stack_label='corrected', list_file='hits_0to2.lst', exclude_stacks='raw_counts',\n",
    "                            client=client, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the integration\n",
    "...is virtually identical to the (Re-)Integration step in `indexing.ipynb`.\n",
    "Just make a `.sol` file for your new data set and fire up `indexamajig --indexing=file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsname = 'hits_0to2'\n",
    "# ds_0to2_hit = Dataset.from_files(dsname + '.lst', open_stacks=False)\n",
    "ds_0to2_hit.get_indexing_solution('master.stream', sol_file=dsname + '.sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN THIS ---------------\n",
      "/opts/crystfel_latest/bin/indexamajig -g refined.geom -i hits_0to2.lst -o streams/hits_0to2.stream -j 40 -p refined.cell --indexing=file --integration=rings-nograd-nocen --int-radius=3,4,6 --peaks=cxi --max-indexer-threads=2 --no-refine --no-retry --no-check-peaks --fromfile-input-file=hits_0to2.sol --copy-hdf5-field=/%/shots/sample --copy-hdf5-field=/%/shots/region --copy-hdf5-field=/%/shots/crystal_id --copy-hdf5-field=/%/shots/run --copy-hdf5-field=/%/shots/adf1 --copy-hdf5-field=/%/shots/adf2 --copy-hdf5-field=/%/shots/lor_hwhm --copy-hdf5-field=/%/shots/center_x --copy-hdf5-field=/%/shots/center_y\n"
     ]
    }
   ],
   "source": [
    "# %mkdir streams\n",
    "copy_fields = ['sample', 'region', 'crystal_id', 'run', \n",
    "               'adf1', 'adf2', 'lor_hwhm', 'center_x', 'center_y']\n",
    "copy_fields = [f'/%/shots/{cf}' for cf in copy_fields]\n",
    "\n",
    "opts.load()\n",
    "cfcall = tools.call_indexamajig(f'{dsname}.lst', 'refined.geom', \n",
    "                                output=f'streams/{dsname}.stream', \n",
    "                                cell='refined.cell', \n",
    "                                im_params=opts.integration_params, \n",
    "                                procs=40, exc='indexamajig',\n",
    "                                fromfile_input_file = f'{dsname}.sol',\n",
    "                                copy_fields=copy_fields)\n",
    "\n",
    "print('--- RUN THIS ---------------')\n",
    "print(cfcall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting to single shots\n",
    "\n",
    "(Advanced)\n",
    "\n",
    "Now, we want to make a corrected and annotated (i.e., including peaks and centers) version of the raw data, i.e., single movie frames, for example to study radiation damage or be flexible during merging.\n",
    "This is done essentially exactly the same as if you were just using a different aggregation (see above), just that instead of `Dataset.aggregate` you just use `Dataset.get_selection` to restrict the range of included frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21460 shots out of 55800 selected.\n",
      "Persisting stacks to memory: \n",
      "Single-file dataset, disabling parallel I/O.\n",
      "No feature list in data set ('/%/map/features not found in image_info.h5.'). That's ok if it's a virtual or info file.\n",
      "Persisting stacks to memory: nPeaks, peakTotalIntensity, peakXPosRaw, peakYPosRaw\n",
      "Persisting stacks to memory: nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n",
      "13220 shots out of 21460 selected.\n",
      "Persisting stacks to memory: nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n"
     ]
    }
   ],
   "source": [
    "# now, do exactly the same thing as above, but on single-shot data\n",
    "unchunk = False # IMPORTANT: set to True to look at the set with .view(), otherwise set to False\n",
    "\n",
    "ds_sgl = ds.get_selection('frame >= 0 and frame < 10 and shutter_time==2', file_suffix='_allframe.h5', new_folder='proc_data')\n",
    "\n",
    "ds_sgl.merge_pattern_info('image_info.h5')\n",
    "ds_sgl = ds_sgl.get_selection(f'num_peaks > {opts.min_peaks}', file_suffix='_hit.h5')\n",
    "\n",
    "if unchunk:\n",
    "    ds_sgl.rechunk_stacks(1)\n",
    "\n",
    "opts.load()\n",
    "ds_compute = ds_sgl\n",
    "img_final = proc2d.correct_image(ds_compute.raw_counts, opts,\n",
    "                                ds_compute.shots.lor_x.values,\n",
    "                                ds_compute.shots.lor_y.values,\n",
    "                                ds_compute.peak_data) # keep in mind, that this a lazy computation, so nothing is actually done yet\n",
    "\n",
    "ds_compute.add_stack('corrected', img_final, overwrite=True, set_diff_stack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data files...\n",
      "Storing meta tables...\n",
      "Storing meta stacks nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n",
      "[########################################] | 100% Completed |  7.8s\n",
      "Storing diffraction data stack corrected... monitor progress at http://127.0.0.1:8787/status (or forward port if remote)\n",
      "Initializing data sets for diffraction stack corrected...\n",
      "Submitting tasks to dask.distributed scheduler...\n",
      "Starting computation...\n",
      "[########################################] | 100% Completed |  4min  7.2s\r"
     ]
    }
   ],
   "source": [
    "# ...and run the computation\n",
    "dsname = 'hits_allframe'\n",
    "ds_compute.compute_and_save(diff_stack_label='corrected', list_file=f'{dsname}.lst', exclude_stacks='raw_counts',\n",
    "                            client=client, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN THIS ---------------\n",
      "indexamajig -g refined.geom -i hits_allframe.lst -o streams/hits_allframe.stream -j 40 -p refined.cell --indexing=file --integration=rings-nograd-nocen --int-radius=3,4,6 --peaks=cxi --max-indexer-threads=2 --no-refine --no-retry --no-check-peaks --fromfile-input-file=hits_allframe.sol --copy-hdf5-field=/%/shots/frame --copy-hdf5-field=/%/shots/sample --copy-hdf5-field=/%/shots/region --copy-hdf5-field=/%/shots/crystal_id --copy-hdf5-field=/%/shots/run --copy-hdf5-field=/%/shots/adf1 --copy-hdf5-field=/%/shots/adf2 --copy-hdf5-field=/%/shots/lor_hwhm --copy-hdf5-field=/%/shots/center_x --copy-hdf5-field=/%/shots/center_y\n"
     ]
    }
   ],
   "source": [
    "# Finally: integrate Bragg spot intensities, grabbing the indexing\n",
    "# solutions from master.stream\n",
    "# IMPORTANT - 'frame' now has to be in the copy_fields, which allows to\n",
    "# later determine which dose fractionation frame a stream chunk belongs to.\n",
    "dsname = 'hits_allframe'\n",
    "ds_sgl.get_indexing_solution('master.stream', sol_file=dsname + '.sol')\n",
    "\n",
    "# IMPORTANT: NOW 'frame' HAS TO BE IN!\n",
    "copy_fields = ['frame','sample', 'region', 'crystal_id', 'run', \n",
    "               'adf1', 'adf2', 'lor_hwhm', 'center_x', 'center_y']\n",
    "copy_fields = [f'/%/shots/{cf}' for cf in copy_fields]\n",
    "\n",
    "opts.load()\n",
    "cfcall = tools.call_indexamajig(f'{dsname}.lst', 'refined.geom', \n",
    "                                output=f'streams/{dsname}.stream', \n",
    "                                cell='refined.cell', \n",
    "                                im_params=opts.integration_params, \n",
    "                                procs=40, exc='indexamajig',\n",
    "                                fromfile_input_file = f'{dsname}.sol',\n",
    "                                copy_fields=copy_fields)\n",
    "\n",
    "print('--- RUN THIS ---------------')\n",
    "print(cfcall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make cumulative-sum files\n",
    "(Advanced)\n",
    "\n",
    "Finally, you can also create a set of files, which instead of single frames, have their cumulative sums, which means that you can pick in hindsight which ones you want to use for the later steps. \n",
    "Some might prefer a workflow where you just make files for different aggregations (as above) that you think make sense.\n",
    "\n",
    "Anyway - for this case, the function `transform_stack_group` does exactly what you want: a cumulative sum over each group in your stack matching one unique crystal. The rest is as usual.\n",
    "\n",
    "The final cell is a neat trick to split the stream into individual sub-streams for the different aggregations, e.g. for individiual merging, using CrystFELs `stream_grep` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if restarting from here... re-load the single-shot set\n",
    "ds_sgl = Dataset.from_files('hits-allframe.lst', chunking=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13220 shots out of 13220 selected.\n",
      "Persisting stacks to memory: nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n",
      "Persisting stacks to memory: \n"
     ]
    }
   ],
   "source": [
    "# copy data set and apply transform function, which defaults to cumulation\n",
    "ds_cum_0 = ds_sgl.get_selection('True', file_suffix='_cum_from_0.h5')\n",
    "ds_cum_0.transform_stack_groups(stacks='corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data files...\n",
      "Storing meta tables...\n",
      "Storing meta stacks nPeaks, peakXPosRaw, peakYPosRaw, peakTotalIntensity\n",
      "[########################################] | 100% Completed |  5.6s\n",
      "Storing diffraction data stack corrected... monitor progress at http://127.0.0.1:8787/status (or forward port if remote)\n",
      "Initializing data sets for diffraction stack corrected...\n",
      "Submitting tasks to dask.distributed scheduler...\n",
      "Starting computation...\n",
      "[########################################] | 100% Completed |  1min 42.4s\r"
     ]
    }
   ],
   "source": [
    "# run the computation. Depending on your computer and data set size, have a coffee or go to bed now.\n",
    "dsname = 'hits_cum-0'\n",
    "ds_cum_0.compute_and_save(diff_stack_label='corrected', list_file=f'{dsname}.lst', exclude_stacks='raw_counts',\n",
    "                            client=client, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN THIS ---------------\n",
      "/opts/crystfel_latest/bin/indexamajig -g refined.geom -i hits_cum-0.lst -o streams/hits_cum-0.stream -j 40 -p refined.cell --indexing=file --integration=rings-nograd-nocen --int-radius=3,4,6 --peaks=cxi --max-indexer-threads=2 --no-refine --no-retry --no-check-peaks --fromfile-input-file=hits_cum-0.sol --copy-hdf5-field=/%/shots/frame --copy-hdf5-field=/%/shots/sample --copy-hdf5-field=/%/shots/region --copy-hdf5-field=/%/shots/crystal_id --copy-hdf5-field=/%/shots/run --copy-hdf5-field=/%/shots/adf1 --copy-hdf5-field=/%/shots/adf2 --copy-hdf5-field=/%/shots/lor_hwhm --copy-hdf5-field=/%/shots/center_x --copy-hdf5-field=/%/shots/center_y\n"
     ]
    }
   ],
   "source": [
    "# Finally: integrate Bragg spot intensities, grabbing the indexing\n",
    "# solutions from master.stream\n",
    "# IMPORTANT - 'frame' now has to be in the copy_fields, which allows to\n",
    "# later determine which dose fractionation frame a stream chunk belongs to.\n",
    "\n",
    "dsname = 'hits_cum-0'\n",
    "ds_cum_0.get_indexing_solution('master.stream', sol_file=dsname + '.sol')\n",
    "\n",
    "# IMPORTANT: NOW 'frame' HAS TO BE IN!\n",
    "copy_fields = ['frame','sample', 'region', 'crystal_id', 'run', \n",
    "               'adf1', 'adf2', 'lor_hwhm', 'center_x', 'center_y']\n",
    "copy_fields = [f'/%/shots/{cf}' for cf in copy_fields]\n",
    "\n",
    "opts.load()\n",
    "cfcall = tools.call_indexamajig(f'{dsname}.lst', 'refined.geom', \n",
    "                                output=f'streams/{dsname}.stream', \n",
    "                                cell='refined.cell', \n",
    "                                im_params=opts.integration_params, \n",
    "                                procs=40, exc='/opts/crystfel_latest/bin/indexamajig',\n",
    "                                fromfile_input_file = f'{dsname}.sol',\n",
    "                                copy_fields=copy_fields)\n",
    "\n",
    "print('--- RUN THIS ---------------')\n",
    "print(cfcall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up cumulative stream into sub-streams\n",
    "os.environ[\"PATH\"] += os.pathsep + '/opts/dev/crystfel/scripts' # CrystFEL scripts folder\n",
    "for ii in range(10):\n",
    "    if ii == 2:\n",
    "        # for the 0-2 aggregation we already created a stream file!\n",
    "        continue\n",
    "    else:\n",
    "        !stream_grep -i streams/hits_cum-0.stream -o streams/hits_0to{ii}.stream -n header/int//%/shots/frame -eq {ii}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:send]",
   "language": "python",
   "name": "conda-env-send-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "084f53443b634573be16591c64ba1009": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "19bad42a62114d3d8b37f78fcab9f4b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_527e150f51fa4563a4f2e002536716ee",
        "IPY_MODEL_aa6e9bad476e4190a3c6cc13cbf4b669",
        "IPY_MODEL_28f65148eed248aa9d6ef7927e0fcd25",
        "IPY_MODEL_3cc04436e58744debd3330597c5edc4d"
       ],
       "layout": "IPY_MODEL_084f53443b634573be16591c64ba1009"
      }
     },
     "23dd7d1099de48bb86a29583c98be07f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "25a14da3682441a6a6178cfbe514148a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "28f65148eed248aa9d6ef7927e0fcd25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatTextModel",
      "state": {
       "description": "Imax",
       "layout": "IPY_MODEL_92bd70420fc94d6288e71bbda3cb221b",
       "step": null,
       "style": "IPY_MODEL_25a14da3682441a6a6178cfbe514148a",
       "value": 30
      }
     },
     "345900dfc29a40e3923085cb0dc83b40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "35ea91984bbe49ebbea1ec7ab8874ec3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "height": "100%"
      }
     },
     "3884068dbccd45d3960c7d9ad88c0973": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ec237e79f0fa4b0f8aa5101b4cf4b39e",
        "IPY_MODEL_599545a71e3c47c2a26bd5cf02d8f637"
       ],
       "layout": "IPY_MODEL_bd78283a8cf943949fce101249acb83f"
      }
     },
     "3cc04436e58744debd3330597c5edc4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "CheckboxModel",
      "state": {
       "description": "log",
       "disabled": false,
       "layout": "IPY_MODEL_e5f61795fa484264ac4f4d2156b2bbc5",
       "style": "IPY_MODEL_f6fa1a18b70c4e569410922ec78f35b8",
       "value": false
      }
     },
     "4d2efba7052c41b4bad8797e1cc98468": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3884068dbccd45d3960c7d9ad88c0973",
        "IPY_MODEL_19bad42a62114d3d8b37f78fcab9f4b8"
       ],
       "layout": "IPY_MODEL_92706cdb0c244d758b3c62412e5a4c8c"
      }
     },
     "527e150f51fa4563a4f2e002536716ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ToggleButtonModel",
      "state": {
       "description": "selected",
       "layout": "IPY_MODEL_8f11583e61d3433aa9c4be81ba033153",
       "style": "IPY_MODEL_856b47baee4343729a62a78472d758d2",
       "value": true
      }
     },
     "57cf4d3f78d54f109aa9c6740ba45145": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "599545a71e3c47c2a26bd5cf02d8f637": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_e31b4599a70845aeb5c1da537b2975c8",
       "outputs": [
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "a8f7318f610a4629bf6d8b2961489d17",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "71953014221648a9bee8d2c433d52f84": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_9b698eb638064fa7ae004c7f773ae805",
       "orientation": "horizontal",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle\nx/y fixes axis, CTRL fixes aspect",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "76e7da49067c4896865f0c44542ae87c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7f9f2a6f54494210b2eea2a2c7742c23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "856b47baee4343729a62a78472d758d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "86ebe70551be4cf8826075f992413a85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8f11583e61d3433aa9c4be81ba033153": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92706cdb0c244d758b3c62412e5a4c8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92bd70420fc94d6288e71bbda3cb221b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "961546e1423a4afca614f01894634521": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "shot",
       "layout": "IPY_MODEL_dca00a9efbcd4f3da87a12b6dc963e83",
       "max": 1322,
       "style": "IPY_MODEL_23dd7d1099de48bb86a29583c98be07f"
      }
     },
     "9b698eb638064fa7ae004c7f773ae805": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a8f7318f610a4629bf6d8b2961489d17": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "_cursor": "default",
       "_figure_label": "Figure 1",
       "_height": 480,
       "_width": 640,
       "header_visible": false,
       "layout": "IPY_MODEL_86ebe70551be4cf8826075f992413a85",
       "toolbar": "IPY_MODEL_71953014221648a9bee8d2c433d52f84",
       "toolbar_position": "bottom"
      }
     },
     "aa6e9bad476e4190a3c6cc13cbf4b669": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_76e7da49067c4896865f0c44542ae87c",
       "style": "IPY_MODEL_7f9f2a6f54494210b2eea2a2c7742c23",
       "value": "1322 of 1322 shots selected."
      }
     },
     "b8251ad238444c50b45cfde281893ea0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextareaModel",
      "state": {
       "layout": "IPY_MODEL_35ea91984bbe49ebbea1ec7ab8874ec3",
       "style": "IPY_MODEL_57cf4d3f78d54f109aa9c6740ba45145",
       "value": "sample: Lyso190304\nregion: 3\nrun: 0\ncrystal_id: 0\ncrystal_x: 657.0\ncrystal_y: 35.0\npos_x: 640.4\npos_y: 37.700000000000045\nselected: True\nsubset: entry\nshutter_time: 2.0\nagg_len: 3\nfile_raw: raw_data/LysoS1_001_00000.nxs\nEvent_raw: entry//1\nadf1: 23.250854310877912\nadf2: 7.700726806929185\ncenter_refine_score: 2e-20\ncenter_x: 727.6083499592629\ncenter_y: 291.49467675378884\ncom_x: 742.2343501614654\ncom_y: 271.1261102444534\ndet_shift_x_mm: 2.7693481549760937\ndet_shift_y_mm: -1.841653099159282\nlor_hwhm: 8.290220554069863\nlor_pk: 1717.506515335975\nlor_x: 728.1083499592629\nlor_y: 291.99467675378884\nnum_peaks: 23\nii_from: 0\nfile: proc_data/LysoS1_001_00000_0to2_hit.h5\nEvent: entry//0\nshot_in_subset: 0"
      }
     },
     "bd78283a8cf943949fce101249acb83f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0b3f5151e2f49668c6e380e0fba9878": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_fa9d2e3aa62b4e5788895d1ca5a89241"
      }
     },
     "cccf3f4bde154520abf501fb0f0c104f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dadb46fd121f442c8499c73791316d43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [
        "widget-interact"
       ],
       "children": [
        "IPY_MODEL_961546e1423a4afca614f01894634521",
        "IPY_MODEL_28f65148eed248aa9d6ef7927e0fcd25",
        "IPY_MODEL_3cc04436e58744debd3330597c5edc4d",
        "IPY_MODEL_c0b3f5151e2f49668c6e380e0fba9878"
       ],
       "layout": "IPY_MODEL_cccf3f4bde154520abf501fb0f0c104f"
      }
     },
     "dca00a9efbcd4f3da87a12b6dc963e83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e31b4599a70845aeb5c1da537b2975c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e5f61795fa484264ac4f4d2156b2bbc5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec237e79f0fa4b0f8aa5101b4cf4b39e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b8251ad238444c50b45cfde281893ea0",
        "IPY_MODEL_961546e1423a4afca614f01894634521"
       ],
       "layout": "IPY_MODEL_345900dfc29a40e3923085cb0dc83b40"
      }
     },
     "f6fa1a18b70c4e569410922ec78f35b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fa9d2e3aa62b4e5788895d1ca5a89241": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
