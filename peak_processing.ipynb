{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# useful for development work\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import hdf5plugin # required to access LZ4-encoded HDF5 data sets\n",
    "import matplotlib.pyplot as plt\n",
    "from diffractem import tools, proc_peaks, version, pre_proc_opts\n",
    "from diffractem.dataset import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import io\n",
    "from scipy.optimize import least_squares, minimize\n",
    "from numpy import fft\n",
    "import dask as da\n",
    "\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell and geometry refinement from Bragg peaks\n",
    "This notebook exclusively acts on the Bragg peaks found during preprocessing, and mostly uses the functionality provided by `diffractem.proc_peaks`.\n",
    "Currently, this comprises:\n",
    "- Refinement elliptic distortion of the patterns. Note that distortion correction does *not* require a calibration sample, it can be done using the data itself. If the d-spacings are known (or some of them, at least), the camera length can be calibrated, too.\n",
    "- Computation of a virtual powder pattern, and the distribution of peak distances from all diffraction patterns. The latter is most useful to determine the cell parameters, as the lengths of the primitive unit cell should clearly show up at low resolution.\n",
    "- Auto-Refinement of the unit cell using the previously computed powder and distances patterns. The final cell can be exported in CrystFEL format.\n",
    "\n",
    "First, load a data set and get all peak-related data. An `image_info.h5`-type file as is created by `proc2d.get_pattern_info` serves the purpose perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_files('image_info.h5', chunking=-1)\n",
    "pkd = da.compute({k: v for k, v in ds.stacks.items() if 'peak' in k.lower()})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ellipticity refinement\n",
    "Residual elliptical distortions of the pattern are inevitable in a TEM and significantly impact the quality of indexing and integration. Luckily, they can be accounted for easily. Their values are stored in the configuration `.yaml` file. For a first check, just run this cell and modify the values initially loaded from the file to your liking. The analysis is then done on a 2D histogram of peak positions in polar coordinates (radius, azimuth), that is an azimuthally resolved (\"segmented\") powder pattern. Adjust `rad_range` such that you have a couple of strong lines visible.\n",
    "\n",
    "If those lines are rather waves, your ellipticity is not well corrected. To get close to the proper values, play with the parameters in `preproc.yaml` until you smooth them out. On the right panel you see the square of the mean pattern, and the product of the ring pattern with itself rotated by 90°. Make those two curves match as closely as possible.\n",
    "The two values in the caption also give a good indication: make the ellipticity variance small, and the quadrant correlation large.\n",
    "And have fun!\n",
    "\n",
    "Spoiler: in this data set, the ratio is 1.023 and the angle 83°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ellipticity checker\n",
    "opts = pre_proc_opts.PreProcOpts('preproc.yaml')\n",
    "\n",
    "# radial range to show (in pixels)\n",
    "rad_range = (10, 80)\n",
    "\n",
    "peakdata = proc_peaks.get_pk_data(pkd['nPeaks'], pkd['peakXPosRaw'], pkd['peakYPosRaw'], \n",
    "                                  ds.shots.center_x.values, \n",
    "                                  ds.shots.center_y.values, \n",
    "                                  opts=opts,\n",
    "                                  return_vec=False)\n",
    "\n",
    "az = np.arctan2((opts.y_scale*peakdata['peakYPosCor']), peakdata['peakXPosCor']).ravel()\n",
    "tt = (((opts.y_scale*peakdata['peakYPosCor'])**2 + peakdata['peakXPosCor']**2)**.5).ravel()\n",
    "\n",
    "# powder pattern in polar coordinates\n",
    "powder_polar = np.histogram2d(tt, az*180/np.pi, \n",
    "                              bins=[np.linspace(*rad_range, 200), np.linspace(-180, 180, 20)])\n",
    "corr = powder_polar[0] * np.roll(powder_polar[0], powder_polar[0].shape[1]//4, axis=1)\n",
    "\n",
    "plt.close('all')\n",
    "fh, ax = plt.subplots(1, 2, figsize=(8,5), sharey=True)\n",
    "ax[0].pcolormesh(powder_polar[2][:-1], powder_polar[1][:-1], powder_polar[0])\n",
    "ax[0].set_xlabel('Azimuth (deg)')\n",
    "ax[0].set_ylabel('Corrected radius')\n",
    "ax[1].plot(np.nanmean(powder_polar[0]**2, axis=1), powder_polar[1][:-1], label='Mean squared pattern')\n",
    "ax[1].plot(np.nanmean(corr, axis=1), powder_polar[1][:-1], label='Quadrant correlation')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Mean squared counts')\n",
    "\n",
    "plt.title(f'Median ellipticity variance: {np.nanmedian((np.nanvar(powder_polar[0], axis=1)/np.nanmean(powder_polar[0],axis=1))):.2f} \\n'\n",
    "         f'Rel. quadrant correlation: {np.mean(corr)/np.mean(powder_polar[0]**2):.3g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ellipticity grid search\n",
    "Once you're close, but not quite sure, you can run a grid search over angles and ellipticity to find the optimum. The correlations are computed in parallel for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.arange(80, 90, 1)\n",
    "ratio = np.arange(1.02, 1.03, 0.0005)\n",
    "\n",
    "def cost(p):\n",
    "    peakdata = proc_peaks.get_pk_data(pkd['nPeaks'], pkd['peakXPosRaw'], pkd['peakYPosRaw'], \n",
    "                                  ds.shots.center_x.values, \n",
    "                                  ds.shots.center_y.values, \n",
    "                                  opts=opts, \n",
    "                                  return_vec=False, \n",
    "                                      el_rat=p[0], el_ang=p[1])\n",
    "\n",
    "    az = np.arctan2((opts.y_scale*peakdata['peakYPosCor']), peakdata['peakXPosCor']).ravel()\n",
    "    tt = (((opts.y_scale*peakdata['peakYPosCor'])**2 + peakdata['peakXPosCor']**2)**.5).ravel()\n",
    "    powder_polar = np.histogram2d(tt, az*180/np.pi, \n",
    "                                  bins=[np.linspace(*rad_range, 200), np.linspace(-180, 180, 20)])\n",
    "    \n",
    "    return np.mean(powder_polar[0]**2)/np.mean(powder_polar[0] * np.roll(powder_polar[0], powder_polar[0].shape[1]//4, axis=1)) - 1\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "X, Y = np.meshgrid(ratio, angles)\n",
    "with ProcessPoolExecutor() as exc:\n",
    "    foms = exc.map(cost, zip(X.ravel(), Y.ravel()))\n",
    "foms = np.array(list(foms)).reshape(X.shape)\n",
    "\n",
    "# show result\n",
    "plt.figure()\n",
    "plt.pcolormesh(ratio, angles, foms)\n",
    "plt.colorbar()\n",
    "plt.ylabel('Elliptical axis')\n",
    "plt.xlabel('Ellipticity')\n",
    "plt.title('Ellipticity correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize\n",
    "...after having found the optimal geometry.\n",
    "*Please make sure to enter the found optimal ellipticity into your `.yaml` file in any case!*\n",
    "\n",
    "Also, run `tools.update_det_shift` on _all_ datasets that you have already, in this example `hits_agg.lst`.\n",
    "You can achieve that using `tools.update_det_shift` without actually opening the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pre_proc_opts.PreProcOpts('preproc.yaml')\n",
    "tools.make_geometry(opts, 'refined.geom')\n",
    "ds.update_det_shift('preproc.yaml') # we have image_info.h5 open already... so not use tools\n",
    "ds.store_tables(shots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.update_det_shift('hits_agg.lst', 'preproc.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do the same, with parsing geometry file from CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Powder Pattern\n",
    "A quick look, with and without intensity scaling - just to get a feeling. It should look nice and crisp. If it does, proceed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.load()\n",
    "plt.figure()\n",
    "peakdata = proc_peaks.get_pk_data(pkd['nPeaks'], pkd['peakXPosRaw'], pkd['peakYPosRaw'], \n",
    "                                  ds.shots.center_x.values, \n",
    "                                  ds.shots.center_y.values, pk_I=pkd['peakTotalIntensity'], \n",
    "                                  opts=opts, return_vec=True)\n",
    "powder, svec = np.histogram(10/peakdata['peakD'].ravel(), bins=np.linspace(0.3,3,1000))\n",
    "plt.plot(svec[:-1], powder, 'k');\n",
    "plt.xlabel('Scattering vector (1/nm)')\n",
    "plt.ylabel('Frequency')\n",
    "ax2 = plt.twinx()\n",
    "powder, svec = np.histogram(10/peakdata['peakD'].ravel(), bins=np.linspace(0.3,3,1000), \n",
    "                            weights=peakdata['peakTotalIntensity'].ravel(), density=True)\n",
    "ax2.plot(svec[:-1], powder, 'r')\n",
    "ax2.set_ylabel('Rel. Intensity')\n",
    "ax2.yaxis.label.set_color('r')\n",
    "plt.title('Scattering vector distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate peak pair distribution\n",
    "Now, for each pattern, the autocorrelation function of peak positions in each diffraction pattern is computed: \n",
    "$$\n",
    "\\mathrm{ACF}(\\Delta x, \\Delta y) = \\sum_i \\sum_j w_{ij}\\delta(x_i - x_j, y_i - y_j),\n",
    "$$\n",
    "where $(x_i, y_i)$ are the positions of the found peaks, $w_{ij}=1$ for `I=None` and $w_{ij}=I_i\\cdot I_j$ if peak intensities are provided as argument.\n",
    "Ther result will have strong peaks around typical peak distances, that, especially for near-zone-axis patterns, correspond to low-lying d-spacings, down to the primitive unit cell lengths.\n",
    "\n",
    "Both 2D autocorrelations (with peak distance vectors) and their radial projection (just containing peak distances) are computed. The former could be used as input for an EDIFF-type cell finding algorithm [Jiang et al. 2009, doi:10.1107/S0907444909003163], whereas the latter is used for unit-cell refinement.\n",
    "\n",
    "Finally a plot is shown containing the found radial distribution and the virtual powder. If everything goes well, there should be strong coinciding peaks. However the pair distance distribution should have some very strong peaks at low resolutions that are absent from the normal powder pattern. Those will mostly contribute to refinement below.\n",
    "\n",
    "Mind that this computation can take a while. Important parameters are `oversample` - which defines how precisely the actual peak positions are used (i.e., how \"super-resolution\" the result will be), and the minimum d-spacing that you're interested in (set by `d_min`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_min = 4\n",
    "oversample = 4\n",
    "shot_selection = peakdata['nPeaks'] > 20\n",
    "\n",
    "out_rad = int((opts.wavelength / d_min) / (opts.pixel_size / opts.cam_length)) + 1\n",
    "acfs, r_acfs = proc_peaks.get_acf(peakdata['nPeaks'][shot_selection], \n",
    "                                  peakdata['peakXPosCor'][shot_selection,:], \n",
    "                                  peakdata['peakYPosCor'][shot_selection,:],\n",
    "                                  I = None,\n",
    "                                  output_radius=out_rad, roi_length=512, \n",
    "                                  oversample=oversample)\n",
    "\n",
    "# scattering vector axis for distances\n",
    "s_d = np.arange(r_acfs.shape[1]) * opts.pixel_size/opts.cam_length/(.1*opts.wavelength)/oversample\n",
    "\n",
    "fh, axh = plt.subplots(2,1, figsize=(8,5), sharex=True)\n",
    "powder, svec = np.histogram(10/peakdata['peakD'].ravel(), bins=np.linspace(0.3,s_d.max(),len(s_d)))\n",
    "axh[0].plot(svec[1:]/2 + svec[:-1]/2, powder, color='b')\n",
    "axh[0].legend(['Peak resolution distribution'])\n",
    "axh[0].grid(True)\n",
    "axh[1].plot(s_d,r_acfs.mean(axis=0), color='r')\n",
    "axh[1].set_xlabel('Scattering vector (1/nm)')\n",
    "axh[1].legend(['Peak pair distance distribution'])\n",
    "axh[1].grid(True)\n",
    "axh[0].set_title('Virtual powder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine unit cell\n",
    "...from distance distribution and/or virtual powder. Here it's done in two steps: first using the distances (which are sensitive to the primitive cell lengths and immediately should snap on them), then using the virtual powder (which might be a bit sharper especially at high resolutions). Finally, the refined unit cell is exported to a CrystFEL cell file. All is done using a `proc_peaks.Cell` object, which provides a `refine_powder` method that does it pretty much automatically.\n",
    "\n",
    "In practice, it might be good enough to just use the distances (or the powder, if you know you're already close).\n",
    "\n",
    "Note that if you find that all lengths proportionally deviate from your expectation, it's not unlikely that your camera length is off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine peaks using cross-correlation, derivative, or distance metric\n",
    "# set initial cell\n",
    "C0 = proc_peaks.Cell.tetragonal(78, 38, 'P')\n",
    "\n",
    "# define minimum d-spacings for the refinement\n",
    "dmin_d = 13 # for distances\n",
    "dmin_p = 10 # for powder\n",
    "\n",
    "# get powder pattern. Tweak histogram bins such that it looks smooth but detailed.\n",
    "powder, s_p = np.histogram(10/peakdata['peakD'].ravel(), bins=np.linspace(0.3,10/dmin_p,300), density=True)\n",
    "s_p = s_p[1:]/2 + s_p[:-1]/2\n",
    "\n",
    "# get average distance distribution\n",
    "distance = r_acfs.mean(axis=0)\n",
    "\n",
    "C0.init_hkl(dmin_d)\n",
    "C_d, par_d = C0.refine_powder(s_d, distance, method='distance', min_prom=0.2, length_bound=2)\n",
    "print('Initial cell: ', C0)\n",
    "print(f'Distance refinement: {par_d[\"lsq_result\"].x.round(2)}: {par_d[\"initial_cost\"]:.2g} -> {par_d[\"lsq_result\"].cost:.2g}')\n",
    "\n",
    "C_d.init_hkl(dmin_p)\n",
    "C_p, par_p = C_d.refine_powder(s_p, powder, method='distance', min_prom=0.4, length_bound=2)\n",
    "print(f'Powder refinement: {par_p[\"lsq_result\"].x.round(2)}: {par_p[\"initial_cost\"]:.2g} -> {par_p[\"lsq_result\"].cost:.2g}')\n",
    "\n",
    "# make a plot for powder-refinement results\n",
    "plt.close('all')\n",
    "fh, axh = plt.subplots(1,1, figsize=(8,5), sharex=True)\n",
    "plt.vlines(10/C0.d(unique=True), 0, powder.max(), color='g', alpha=0.2)\n",
    "plt.vlines(10/C_d.d(unique=True), 0, powder.max(), color='r', alpha=0.2)\n",
    "plt.vlines(10/C_p.d(unique=True), 0, powder.max(), color='b', alpha=0.2)\n",
    "plt.plot(s_p, powder, color='b')\n",
    "plt.plot(par_p['peak_position'], par_p['peak_height'], 'bx')\n",
    "ax2 = axh.twinx()\n",
    "ax2.plot(s_d,distance, color='r')\n",
    "ax2.plot(par_d['peak_position'], par_d['peak_height'], 'rx')\n",
    "plt.xlim(0, max(10/dmin_d, 10/dmin_p))\n",
    "plt.xlabel('Scattering vector (1/nm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export cell\n",
    "Finally, export the refined cell in CrystFEL format. You're now well set up for indexing. See `indexing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_p.export('refined.cell')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:send]",
   "language": "python",
   "name": "conda-env-send-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
