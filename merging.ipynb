{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from diffractem import io, tools\n",
    "from diffractem.stream_parser import StreamParser, make_substream\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "bin_path = '/opts/crystfel_master/bin/' # might be different than standard\n",
    "from glob import glob\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and first validation of serial data sets\n",
    "...from stream files, mostly using `partialator`, `ambigator`, `check_hkl` and `compare_hkl` from CrystFEL, plus some nice plotting functions. Handles parallel processing of merging runs with different parameters and/or input stream files, as well as creation of custom-split files.\n",
    "\n",
    "Contains the following parts:\n",
    "* Pre-processing of stream files, e.g. for making sub-streams by random sampling, or preparing split-lists\n",
    "* Generation of a command script for partilator, which runs it with a bunch of different settings, either directly in a shell, or by submission to a SLURM queue\n",
    "* Batch analysis of `hkl` files using CrystFEL's tools (in parallel) and results parsing\n",
    "* Plotting of results as function of resolution shell and crystal number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Polishing stream-files\n",
    "...which contain the indexing solutions and integrated intensities from each shot. \n",
    "Here, you might e.g. want to generate a file for `custom-split` (see `man partialator`), or to generate stream files with random subsets of events. \n",
    "If non-random subsets (e.g. the first N crystals) are also ok, you can use `partialator`'s `start-after` and `stop-after` options instead!\n",
    "\n",
    "**If you don't care about any of this, you can skip this section and proceed to Step 2**\n",
    "\n",
    "We start by loading the stream file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stream = StreamParser('streams/hits_0to2.stream')\n",
    "print(f'Stream file contains {stream.num_crystals} crystals in {stream.num_shots} shots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random sub-sampling\n",
    "Creates stream-files with *random* subsets of shots and suffix `-N_<# of crystals>.stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_range = list(range(200, stream.num_crystals, 200)) + [stream.num_crystals]\n",
    "\n",
    "with ThreadPoolExecutor() as exc:\n",
    "    Ntotal = (stream.shots.indexed_by != 'none').sum() \n",
    "    exc.map(lambda N: make_substream(stream, N, \n",
    "                                     filename=stream.filename.rsplit('.',1)[0] + f'-N_{N}.stream', \n",
    "        query='indexed_by != \"none\"'), subset_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom-split file\n",
    "Creates a custom-split file for the stream from some parameter in `stream.shots`. This can be very useful e.g. if you want to run a stream containing many time-points (or aggregations) of the same crystals, which you want to scale consistently (example 1).\n",
    "For many other interesting applications, you may have to bin the parameters first, though.\n",
    "This is shown here for the example of `profile_radius`, for which we will do a quantile-based binning (example 2). (Note that this is will not be used later on... it's just an example!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: dose-fractionation frames.\n",
    "# only works if the stream file is from a multi-frame dataset\n",
    "split_data = stream.shots[['file', 'Event', 'hdf5/%/shots/frame']]\n",
    "split_data.to_csv(stream.filename.rsplit('.', 1)[0] + '_split.txt', index=False, header=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2: profile radius\n",
    "n_quantiles = 4 # number of quantile groups.\n",
    "\n",
    "pr = stream.shots.profile_radius.str.split(expand=True)[0].astype(float)\n",
    "group = (pd.qcut(pr, n_quantiles, labels=False)+1).fillna(0).astype(int)\n",
    "split_data = pd.concat([stream.shots[['file', 'Event']], group], axis=1)\n",
    "split_data.to_csv(stream.filename.rsplit('.', 1)[0] + '_split.txt', index=False, header=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparation of a partialator script\n",
    "...which can run partialator with a range of different settings, in order to find the one that fits your data best.\n",
    "The partialator parameters are all set in the `popts` dictionary.\n",
    "Please consult the parameter descriptions available via `man partialator`.\n",
    "If you put a list in any of them, `partialator` will be run in all possible combinations.\n",
    "In this example we use `stop-after` to get a range of different crystal numbers (we might as well have used the random sampling from streams as shown above) and test two merging models.\n",
    "\n",
    "It comes in different flavors - either for direct execution, or for submission to a SLURM queue, depending on what you set for the `slurm` argument\\*.\n",
    "If you want a custom-split, set `split=True` and create a split list file with the same name and path as the stream file and ending `_split.txt` - see examples above how to make it.\n",
    "We will however not work with this for now.\n",
    "\n",
    "`call_partialator` will create a script file `partialator_run.sh` and return a `DataFrame` containing a list of the settings with which partialator is run, and what the filename will be.\n",
    "\n",
    "\\*(Note that, unlike with `call_indexamajig_slurm`, no further options are available to e.g. make an archive file for transfer. \n",
    "Just copy the script and your stream file(s) to the cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a list of stream files\n",
    "stream_list = glob('streams/*.stream')\n",
    "\n",
    "popts = {'no-polarisation': True, 'no-Bscale': False, 'no-scale': False, \n",
    "        'force-bandwidth': 2e-5,  'force-radius': False, 'force-lambda': 0.0251,\n",
    "            'push-res': 1.4,  'min-measurements': [3, ], 'model': ['unity', 'xsphere'],\n",
    "            'symmetry': '422', 'stop-after': list(range(200, 1147, 200)) + [1147],\n",
    "            'no-logs': False, 'iterations': 3, 'j': 10}\n",
    "\n",
    "# you need to set those if you want to use slurm to submit merging runs\n",
    "slurm_opts = {'C': 'scratch', \n",
    "                'partition': 'medium', \n",
    "                'time': '\"04:00:00\"',\n",
    "                'nodes': 1}\n",
    "\n",
    "tools.call_partialator(stream_list, popts, par_runs=4, \n",
    "                       split=False, out_dir='merged',\n",
    "                       slurm=False, cache_streams=False, \n",
    "                       slurm_opts=slurm_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example how to send data to a cluster\n",
    "# !scp -r streams rbuecke1@transfer.gwdg.de:~/SHARED/EDIFF/temp\n",
    "!scp partialator_run.sh rbuecke1@transfer.gwdg.de:~/SHARED/EDIFF/temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example how to get it back from a cluster\n",
    "# %mkdir merged\n",
    "# !scp 'rbuecke1@transfer.gwdg.de:~/SHARED/EDIFF/temp/merged/*.hkl*' merged/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Step 3: Analyze and validate results\n",
    "...assuming your partialator run has finished, and using CrystFELs `check_hkl` and `compare_hkl` tools. The results are parsed into _pandas_ DataFrames using `tools.analzye_hkl` and automatically labeled. While `overall` contains the overall figures of merit for all data frames, `sd` is a flat list of all per-shell and per-setting FOMs. You can use pandas' `groupby` and `pivot` features to get from this table whatever you need conveniently.\n",
    "\n",
    "Finally, plots of figures of merit vs. resolution shell can be generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse available files\n",
    "If you haven't just run the merging before, but started from here, you need a `settings` DataFrame to get started.\n",
    "This cell does that for you, mostly rather accurately, using `tools.get_hkl_settings`.\n",
    "It can then also be used to reject some settings from further analysis (not needed now, but examples are in comments), or mangle with the data columns to have more convenient indicators (done here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what hkls we have available....\n",
    "settings = tools.get_hkl_settings('merged/*.hkl', unique_only=True, custom_split=True)\n",
    "\n",
    "# reject some for analysis...\n",
    "# settings = settings.query('model != \"random\"')\n",
    "# settings = settings.loc[settings.input.str.contains('v_2')]\n",
    "# settings.drop(columns='input', inplace=True)\n",
    "\n",
    "# or do some name mangling... (here: make sure that the folder is stripped of the stream)\n",
    "if 'input' in settings.columns:\n",
    "    settings['input'] = settings['input'].str.rsplit('/', 1, expand=True).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the analysis\n",
    "This is done using the `tools.analyze_hkl` function.\n",
    "However, as the analysis is single-threaded, we can get much faster by doing it in parallel using a `ProcessPoolExecutor` (see the documentation of the `concurrent.futures` package if you want to know more.\n",
    "Concise tables of the results are written into the `shell/` subdirectory.\n",
    "\n",
    "(if there is trouble with finding the CrystFEL executables, set the bin_path parameter manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_symmetry = '422'\n",
    "highres = 1.75 # highest shell, in A\n",
    "nshells = 10\n",
    "\n",
    "# tools.analyze_hkl() #...is used using ProcessPoolExecutor\n",
    "\n",
    "ftrs = {}\n",
    "with ProcessPoolExecutor() as exc:\n",
    "    for _, s in settings.iterrows():\n",
    "        ftrs[s.hklfile] = exc.submit(tools.analyze_hkl, fn=s.hklfile, cell='refined.cell', \n",
    "                              point_group=s.symmetry if 'symmetry' in s else default_symmetry, \n",
    "                              highres=highres, nshells=nshells, bin_path='/opts/crystfel_master/bin')    \n",
    "\n",
    "err = {lbl: v.exception() for lbl, v in ftrs.items() if v.exception()}\n",
    "if err:\n",
    "    print('Analysis gave errors!', str(err))\n",
    "out = {lbl: v.result() for lbl, v in ftrs.items() if not v.exception()}\n",
    "\n",
    "sd = pd.concat([v.result()[0].assign(hklfile=lbl) \n",
    "                for lbl, v in ftrs.items() \n",
    "                    if not v.exception()], axis=0).merge(\n",
    "    settings, on='hklfile')\n",
    "\n",
    "overall = pd.concat([pd.DataFrame(v.result()[1], index=[lbl])\n",
    "                for lbl, v in ftrs.items() \n",
    "                     if not v.exception()], axis=0).merge(\n",
    "    settings, right_on='hklfile', left_index=True).rename(\n",
    "    columns={'<snr>': 'SNR', 'redundancy': 'Red', 'completeness': 'Compl', 'CC*': 'CCstar'})\n",
    "\n",
    "# write out results\n",
    "%rm -f shell/*\n",
    "for ident, grp in sd.groupby(['hklfile']):\n",
    "    grp.sort_values('Center 1/nm')[['Center 1/nm', 'nref', 'Possible', 'Compl', 'Meas', 'Red', 'SNR',\n",
    "           'Std dev', 'Mean', 'd/A', 'Min 1/nm', 'Max 1/nm', 'CC', 'CCstar',\n",
    "           'Rsplit']].to_csv(f'shell/{ident.rsplit(\"/\",1)[-1]}.csv', index=False, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example to show results\n",
    "...using the result DataFrame's `pivot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenient function to get FOMs. Set the one you want as 'value'\n",
    "sd.pivot(index='d/A', columns='hklfile', values=['CC']).sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analysis Plots\n",
    "...ideally using an interactive backend, like `qt`, or `widget`. You can choose which 4 FOMs to plot as a function of resolution, and their display ranges. \n",
    "From the $CC=1/7$, or $CC^*=1/2$ criterion (which are automatically drawn if you ask for those), we can read off a reasonable cut-off for resulution. \n",
    "To learn about what FOMs you can plot, please look at `sd.columns`.\n",
    "The `sdsel=sd.query(......)` allows you to only plot a sub-selection - e.g. here only the full set with unity merging, but all aggregations.\n",
    "\n",
    "In the first line, you can choose your matplotlib backend. `widget` is highly recommended (interactive), but may not always work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 1: Figures of Merit vs resolution shell\n",
    "You can pick subsets of merging runs using `sd.query`, and set the x axis by setting `angstrom`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "# SETTINGS ---\n",
    "\n",
    "fh, axs = plt.subplots(2, 2, figsize=(18/2.54,15/2.54), dpi=120, sharex=True)\n",
    "lsp, lrow = 0.85, 3 # space near top left for legend, and # of legend columns\n",
    "\n",
    "# pick your FOMs and their y ranges\n",
    "FOMs = [('CC', 0, 1), ('Mean', 0, 100), ('Compl', 0, 100), ('Red', 0, 100)]\n",
    "sdsel = sd.query('stop_after > 1000')\n",
    "angstrom = False # if True, show x axis in A, instead of 1/nm\n",
    "\n",
    "# ------\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set('notebook','whitegrid') # optional. Set a style...\n",
    "except:\n",
    "    print('Seaborn not installed, it seems.')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "# ids = get_id_table(sdsel['identifier'])\n",
    "idcols = [cn for cn, col in sdsel[settings.columns].iteritems() \n",
    "          if len(col.unique()) > 1 and (cn != 'hklfile')]\n",
    "print('Legend is', ' '.join(idcols))\n",
    "\n",
    "for ident, grp in sdsel.groupby(['hklfile']):\n",
    "    \n",
    "    ls = '-'\n",
    "     \n",
    "    lbl = tuple(grp[idcols].drop_duplicates().values.astype(str).ravel())\n",
    "    \n",
    "    for ax, (fom, ymin, ymax) in zip(axs, FOMs):\n",
    "        ax.plot(grp['d/A'] if angstrom else grp['Center 1/nm'], grp[fom], \n",
    "                label=' '.join(lbl), ls=ls)\n",
    "        ax.set_title(fom)\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "        if angstrom:\n",
    "            ax.set_xlim(sorted(ax.get_xlim(), reverse=True))\n",
    "        ax.grid(True)\n",
    "        if fom in ['CC', 'CCstar']:\n",
    "            ax.axhline(0.143 if fom == 'CC' else 0.5,ls=':')\n",
    "        \n",
    "lg = fh.legend(*ax.get_legend_handles_labels(), ncol=lrow, \n",
    "               fontsize='xx-small', loc='lower center', \n",
    "               bbox_to_anchor=(0.5, lsp), frameon=True)\n",
    "axs[-1].set_xlabel(r'Resolution shell/Å' if angstrom else r'Resolution shell/nm$^{-1}$')\n",
    "plt.draw()\n",
    "# lpos = lg.get_window_extent()\n",
    "\n",
    "fh.subplots_adjust(wspace=0.3, top=lsp-0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig. 2: overall and single-shell FOM vs. crystal number.\n",
    "Obviously only makes sense for data sets which have multiple crystal numbers. If you did not define this using `stop_after` or `start_after`, you'll have to mangle around with e.g. hklfile names yourself before. The plots display values of a selected shell in dashed lines, which you can pick in the variable `res`. The available values are printed when running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS ---\n",
    "\n",
    "N_col = 'stop_after' # column containing the number of crystals\n",
    "\n",
    "fh, axs = plt.subplots(2,2,figsize=(18/2.54,15/2.54),dpi=120,sharex=True)\n",
    "\n",
    "# pick your FOMs and their y ranges\n",
    "FOMs = [('CC', 0, 1), ('Compl', 0, 100), ('Rsplit', 0, 100), ('Red', 0, 50)]\n",
    "\n",
    "# resolution bin for dashed plot\n",
    "res = 1.85\n",
    "# ovsel = overall.query('input in [\"0to1.stream\", \"0to2.stream\", \"0to8.stream\"]')\n",
    "ovsel = overall\n",
    "\n",
    "# -----\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set('notebook','whitegrid') # optional. Set a style...\n",
    "except:\n",
    "    print('Seaborn not installed, it seems.')\n",
    "    \n",
    "axs = axs.ravel()\n",
    "\n",
    "idcols = [cn for cn, col in sd[settings.columns].iteritems() \n",
    "          if len(col.unique()) > 1 and (cn not in  ['hklfile', N_col])]\n",
    "\n",
    "print('Available resolution bins are', ' '.join(sd['d/A'].unique().astype(str)))\n",
    "print('Legend is', ' '.join(idcols))\n",
    "\n",
    "for idcol, grp in ovsel.groupby(idcols if len(idcols) else np.ones(len(ovsel))):\n",
    "    \n",
    "    sdsel = sd.merge(grp, on='hklfile', validate='m:1', suffixes=('','_ov'))\n",
    "    sdsel = sdsel[sdsel['d/A'] == res].sort_values(N_col)\n",
    "    \n",
    "    grp = grp.sort_values(N_col)\n",
    "    lbl = tuple(grp[idcols].drop_duplicates().values.astype(str).ravel())\n",
    "    for ax, (fom, xmin, xmax) in zip(axs, FOMs):\n",
    "        ph = ax.plot(grp[N_col], grp[fom], label=' '.join(lbl), ls='-')\n",
    "        ax.plot(sdsel[N_col], sdsel[fom], color=ph[0].get_color(), ls='--')\n",
    "        ax.set_title(fom)\n",
    "        ax.set_ylim((xmin, xmax))\n",
    "        ax.grid(True)\n",
    "        if fom in ['CC', 'CCstar']:\n",
    "            ax.axhline(0.143 if fom == 'CC' else 0.5,ls=':')\n",
    "        \n",
    "axs[-1].legend(ncol=2, fontsize='xx-small')\n",
    "axs[-1].set_xlabel(r'Crystal number')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: publication-ready plots\n",
    "Another plot section, which is more dataset-specific and less convenient, but really makes good plots for final reports with slightly more effort. \n",
    "Needs to be adapted to each dataset manually, so you'll have to do that if you copied this notebook from another dataset.\n",
    "\n",
    "**This is _not_ part of the general workflow tutorial - generally most likely it will not work without customization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versus Resolution shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rc('axes', titleweight='normal', labelweight='normal')\n",
    "\n",
    "# Dataset-separated FOM vs resolution plot\n",
    "import seaborn as sns\n",
    "sns.set('paper','whitegrid') # optional. Set a style...\n",
    "\n",
    "FOMs = [(['CC', None], 0, 1, '$CC_{1/2}$'), \n",
    "        (['Compl', None], 0, 100, 'Completeness'),\n",
    "       (['Red', None], 0, 50, 'Redundancy')]#, R_\\mathrm{work}$ (dashed)')]\n",
    "\n",
    "# select the data subset to show. Add \"cmp\" to the method list if you want relative data\n",
    "sd_sel = sd.query(f'stop_after > 1000 and input in [\"0to1.stream\", \"0to2.stream\", \"0to8.stream\"]')\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "fh, axs= plt.subplots(len(FOMs), 1, figsize=(8.5/2.54, 15/2.54), sharex=True, dpi=300,\n",
    "                      gridspec_kw={'hspace':0.1, 'wspace':0.1, 'height_ratios': [1]*len(FOMs)})\n",
    "\n",
    "# The 'zzz' rename is required to put the plots in proper order\n",
    "last_model = ''\n",
    "for (model, agg, hklfile), grp in \\\n",
    "    sd_sel.groupby(['model', 'input', 'hklfile'], sort=True):\n",
    "    \n",
    "    for ii, (fom, ymin, ymax, cpt) in enumerate(FOMs):    \n",
    "        ax = axs[ii]\n",
    "    \n",
    "        if model != last_model:\n",
    "            ax.set_prop_cycle(None)\n",
    "        \n",
    "        if fom[0] == 'CC':\n",
    "            ax.axhline(0.143, color='k', alpha=0.1)\n",
    "        \n",
    "        lbl = f'{2*int(agg[3])+1} ms' if model=='unity' else ''\n",
    "        src = grp\n",
    "        ph = ax.plot(src['Center 1/nm'], src[fom[0]], \n",
    "                     label=lbl, \n",
    "                     ls='-' if model=='unity' else '--', \n",
    "                     marker='o' if model=='unity' else 'v', markersize=3,\n",
    "                     fillstyle='none')\n",
    "        c = [p.get_color() for p in ph]\n",
    "        if fom[1] is not None:\n",
    "            lbl = None\n",
    "            ax.plot(src['Center 1/nm'], src[fom[1]], \n",
    "                    label=lbl, color=c[0], ls='--',\n",
    "                    marker='o' if model=='unity' else 'v', fillstyle='none')\n",
    "        \n",
    "        # common axis settings\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "        ax.set_xticks([10/d for d in range(6,1,-1)])\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # stuff appearing for specific axes only\n",
    "        if ii == 0:\n",
    "            ax.legend()\n",
    "        ax.set_ylabel(cpt)                 \n",
    "        if ii == (len(FOMs)-1):\n",
    "            ax.set_xlabel('Resolution (Å)')\n",
    "            ax.set_xticklabels([f'{(10/float(l)):.0f}' for l in ax.get_xticks()])\n",
    "        else:\n",
    "            ax.set_xticklabels([])          \n",
    "            \n",
    "    last_model = model\n",
    "            \n",
    "ax.set_xlim(10/4.5, ax.get_xlim()[1])\n",
    "\n",
    "plt.savefig(f'fom_vs_res.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versus Crystal Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: FOMs at fixed resolution/overall vs. crystal number\n",
    "# %matplotlib inline\n",
    "# MAIN TEXT\n",
    "target = 'main'\n",
    "FOMs = [(['CC_ov', 'CC'], 0, 1, '$CC_{1/2}$'), \n",
    "        (['Compl_ov', 'Compl', None], 0, 100, 'Completeness'),\n",
    "       (['Red_ov', 'Red'], 0, 50, 'Redundancy')]\n",
    "\n",
    "# make subset (including carving out the highest shell only)\n",
    "hishell = 1.85\n",
    "sd_sel = sd.loc[sd['d/A'] == hishell,:].sort_index() # xfel9 / ssx9: 0.9.0\n",
    "\n",
    "# merge overall data. Inner merge, so it is sub-selected automatically\n",
    "sd_sel = sd_sel.merge(overall, on=['model', 'input', 'stop_after'], \n",
    "                    how='inner', suffixes=('', '_ov'))\n",
    "\n",
    "# select crystal number range\n",
    "sd_sel = sd_sel.query('input == \"0to2.stream\"')\n",
    "\n",
    "fh, axs= plt.subplots(len(FOMs), 1, figsize=(8.5/2.54, 15/2.54), sharex=True, dpi=150,\n",
    "                      gridspec_kw={'hspace':0.1, 'wspace':0.1, 'height_ratios': [1]*len(FOMs)})\n",
    "\n",
    "for (model, agg), grp in sd_sel.groupby(['model', 'input'], sort=True):\n",
    "    grps = grp.sort_values(by='stop_after').rename(columns={'stop_after': 'crystals'})\n",
    "    \n",
    "    for ii, (fom, ymin, ymax, cpt) in enumerate(FOMs):\n",
    "        ax = axs[ii]\n",
    "        if fom[0] in grps.columns:\n",
    "            ph = ax.plot(grps.crystals, grps[fom[0]], \n",
    "                     label=f'{model}', \n",
    "                     linestyle='-', marker='o' if model=='unity' else 'v', \n",
    "                         fillstyle='none', markersize=3)\n",
    "        if (fom[1] is not None) and (fom[1] in grps.columns):\n",
    "            ax.plot(grps.crystals, grps[fom[1]], \n",
    "    #                 label=f'{method.upper()} ({fom[1]})',\n",
    "                    label = None,\n",
    "                    color=ph[0].get_color(), \n",
    "                    linestyle='--', marker='o' if model=='unity' else 'v', \n",
    "                    fillstyle='none', markersize=3)\n",
    "\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "        ax.set_ylabel(cpt)                 \n",
    "\n",
    "        if (ii == 0):\n",
    "            ax.legend()  \n",
    "        ax.set_xlim(100, 1300)\n",
    "        if ii == (len(FOMs)-1):\n",
    "            ax.set_xlabel('Crystal number')\n",
    "plt.savefig(f'fom_vs_number.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both together\n",
    "...as seen in workflow paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rc('axes', titleweight='normal', labelweight='normal')\n",
    "plt.close('all')\n",
    "\n",
    "# Dataset-separated FOM vs resolution plot\n",
    "import seaborn as sns\n",
    "sns.set('paper','whitegrid') # optional. Set a style...\n",
    "\n",
    "FOMs = [(['CC', None], 0, 1, '$CC_{1/2}$'), \n",
    "        (['Compl', None], 0, 100, 'Completeness'),\n",
    "       (['Red', None], 0, 50, 'Redundancy')]#, R_\\mathrm{work}$ (dashed)')]\n",
    "\n",
    "\n",
    "fh, axs_both = plt.subplots(len(FOMs), 2, figsize=(17/2.54, 15/2.54), sharex=False, sharey=False, dpi=150,\n",
    "                      gridspec_kw={'hspace':0.1, 'wspace':0.1, 'height_ratios': [1]*len(FOMs)})\n",
    "\n",
    "# select the data subset to show. Add \"cmp\" to the method list if you want relative data\n",
    "sd_sel = sd.query(f'stop_after > 1000 and input in [\"0to1.stream\", \"0to2.stream\", \"0to8.stream\"]')\n",
    "\n",
    "axs = axs_both[:, 0]\n",
    "\n",
    "# The 'zzz' rename is required to put the plots in proper order\n",
    "last_model = ''\n",
    "for (model, agg, hklfile), grp in \\\n",
    "    sd_sel.groupby(['model', 'input', 'hklfile'], sort=True):\n",
    "    \n",
    "    for ii, (fom, ymin, ymax, cpt) in enumerate(FOMs):    \n",
    "        ax = axs[ii]\n",
    "    \n",
    "        if model != last_model:\n",
    "#             print(last_model, model)\n",
    "            ax.set_prop_cycle(None)\n",
    "        \n",
    "        if fom[0] == 'CC':\n",
    "            ax.axhline(0.143, color='k', alpha=0.1)\n",
    "        \n",
    "        lbl = f'{2*int(agg[3])+1} ms' if model=='unity' else ''\n",
    "#         lbl = f'{model}, {2*int(agg[3])+1} ms'\n",
    "        src = grp\n",
    "        ph = ax.plot(src['Center 1/nm'], src[fom[0]], \n",
    "                     label=lbl, \n",
    "                     ls='-' if model=='unity' else '--', \n",
    "                     marker='o' if model=='unity' else 'v', markersize=3,\n",
    "                     fillstyle='none')\n",
    "        c = [p.get_color() for p in ph]\n",
    "        if fom[1] is not None:\n",
    "            lbl = None\n",
    "            ax.plot(src['Center 1/nm'], src[fom[1]], \n",
    "                    label=lbl, color=c[0], ls='--',\n",
    "                    marker='o' if model=='unity' else 'v', fillstyle='none')\n",
    "        \n",
    "        # common axis settings\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "        ax.set_xticks([10/d for d in range(6,1,-1)])\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # stuff appearing for specific axes only\n",
    "        if ii == 0:\n",
    "#             ax.set_title('MB ($N=8000$)' if sample=='mb' else 'FAcD ($N=10000$)')\n",
    "            ax.legend(ncol=1)\n",
    "        ax.set_ylabel(cpt)                 \n",
    "        if ii == (len(FOMs)-1):\n",
    "            ax.set_xlabel('Resolution (Å)')\n",
    "            ax.set_xticklabels([f'{(10/float(l)):.0f}' for l in ax.get_xticks()])\n",
    "        else:\n",
    "            ax.set_xticklabels([])         \n",
    "            \n",
    "        ax.set_xlim(10/4.5, ax.get_xlim()[1])\n",
    "                    \n",
    "    last_model = model\n",
    "            \n",
    "# plt.savefig(f'fom_vs_res.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "# PART 2: FOMs at fixed resolution/overall vs. crystal number\n",
    "# %matplotlib inline\n",
    "# MAIN TEXT\n",
    "target = 'main'\n",
    "FOMs = [(['CC_ov', 'CC'], 0, 1, '$CC_{1/2}$'), \n",
    "        (['Compl_ov', 'Compl', None], 0, 100, 'Completeness'),\n",
    "       (['Red_ov', 'Red'], 0, 50, 'Redundancy')]\n",
    "\n",
    "# make subset (including carving out the highest shell only)\n",
    "hishell = 1.85\n",
    "sd_sel = sd.loc[sd['d/A'] == hishell,:].sort_index() # xfel9 / ssx9: 0.9.0\n",
    "\n",
    "# merge overall data. Inner merge, so it is sub-selected automatically\n",
    "sd_sel = sd_sel.merge(overall, on=['model', 'input', 'stop_after'], \n",
    "                    how='inner', suffixes=('', '_ov'))\n",
    "\n",
    "# select crystal number range\n",
    "sd_sel = sd_sel.query('input == \"0to2.stream\"')\n",
    "\n",
    "axs = axs_both[:, 1]\n",
    "\n",
    "for (model, agg), grp in sd_sel.groupby(['model', 'input'], sort=True):\n",
    "    grps = grp.sort_values(by='stop_after').rename(columns={'stop_after': 'crystals'})\n",
    "    \n",
    "    for ii, (fom, ymin, ymax, cpt) in enumerate(FOMs):\n",
    "        ax = axs[ii]\n",
    "        if fom[0] in grps.columns:\n",
    "            ph = ax.plot(grps.crystals, grps[fom[0]], \n",
    "                     label=f'{model}', \n",
    "                     linestyle='-', marker='o' if model=='unity' else 'v', \n",
    "                         fillstyle='none', markersize=3)\n",
    "        if (fom[1] is not None) and (fom[1] in grps.columns):\n",
    "            ax.plot(grps.crystals, grps[fom[1]], \n",
    "    #                 label=f'{method.upper()} ({fom[1]})',\n",
    "                    label = None,\n",
    "                    color=ph[0].get_color(), \n",
    "                    linestyle=':', marker='o' if model=='unity' else 'v', \n",
    "                    fillstyle='none', markersize=3)\n",
    "\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "#         ax.set_ylabel(cpt)       \n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        if (ii == 0):\n",
    "            ax.legend()  \n",
    "        ax.set_xlim(100, 1300)\n",
    "        if ii == (len(FOMs)-1):\n",
    "            ax.set_xlabel('Crystal number')\n",
    "        else:\n",
    "            ax.set_xticklabels([])\n",
    "            \n",
    "plt.savefig(f'fom_all.pdf', transparent=True, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:send]",
   "language": "python",
   "name": "conda-env-send-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
